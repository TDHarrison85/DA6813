---
title: "DA 6813 Case Study 1 "
author: "Will Hytlin, Holly Millazo and Tim Harrison"
date: today
format: 
  html:
    theme: lumen # or flatly, lumen, united, etc.
    toc: true # Adds a table of contents
    toc-depth: 2 # Depth of table of contents
    toc-location: left
    code-fold: true # Folds code by default
    number-sections: true # Numbered sections
    df-print: paged # Nice table format
    fig-align: center # Centers figures
    fig-width: 6 # Adjust figure size
    fig-height: 4
    reference-location: section # Valid value for citation references
---

```{r setup, echo=FALSE}
pacman::p_load(MASS, tidyverse, here, car, corrplot, skimr, caret, ggplot2, dplyr, tidyr, ROCR)
df1 <- read.csv(here('Case Study 1','bank-additional.csv'), sep = ';')
df2 <- df1 %>% mutate_if(is.character, as.factor)
levels(df2$y)
df3 <- df2 %>% mutate(
  pcontact = ifelse(pdays == 999, 0, 1),
  y = ifelse(y == 'yes',1,0)
) %>% select(!pdays)


```

# Executive Summary

<!-- 
Purpose: Provide a concise overview of the key findings and results of the analysis.
Instructions: Summarize the performance of the models (e.g., random forest, decision tree, logistic regression). Highlight the best-performing model and key insights regarding customer acquisition. Avoid technical details, focusing on high-level conclusions that decision-makers would care about.
-->

Content for Executive Summary goes here.

# Problem Statement

<!-- 
Purpose: Explain the problem that the study aims to solve.
Instructions: Clearly define the task at hand, which in this case is predicting customer acquisition. Outline the objectives and what solving this problem would mean for the company.
-->



The task of this case study is to develop a predictive model to classify whether clients of a Portuguese banking institution will subscribe to a term deposit following a direct marketing campaign. The campaigns were based on phone calls, and often, multiple contacts were made to the same client to assess if they would subscribe ('yes') or not ('no'). The goal is to accurately predict the likelihood of a client subscribing to a term deposit based on various input variables, including demographic, social, and economic indicators, as well as information from previous marketing campaigns.

Key variables influencing the prediction include the client's age, job type, marital status, education, and financial status (e.g., default history, housing loan, and personal loan). Additionally, variables related to the marketing campaign, such as the type of contact, day, and month of the last contact, and previous campaign outcomes, are also critical in determining the client’s response. Social and economic context attributes, such as the employment variation rate and consumer confidence index, are included to enhance the model's predictive power.

The primary objective is to build a classification model that can accurately predict whether a client will subscribe to a term deposit. This will allow the bank to target its marketing efforts more effectively, optimizing resource allocation, and improving conversion rates.


# Methodology

<!-- 
Purpose: Describe the methods and processes used to conduct the analysis.
Instructions: Detail the models used and the reasoning behind them. Include specifics such as hyperparameter tuning, data splitting, and assumptions of each model.
-->

The analysis utilized logistic regression as the primary method to predict whether clients would subscribe to a term deposit. The dataset was split into training and testing sets, with 80% of the data used for training and 20% for testing, ensuring that the model could be evaluated on unseen data to prevent overfitting. Multiple iterations of the logistic regression model were run, starting with all relevant variables. Stepwise refinement was used to remove variables that displayed multicollinearity, improving the model's accuracy. **Variance Inflation Factor (VIF)** was employed to check for multicollinearity, which led to the exclusion of variables like **housing**, **nr.employed**, and **emp.var.rate**.

Several key assumptions of logistic regression were taken into account throughout the analysis. First, the assumption of the **linearity of log odds** required the relationship between the predictors and the log odds of the outcome to be linear; variables that did not meet this assumption were either transformed or excluded from the model. The **independence of errors** was also ensured by the random sampling method used during data splitting. **Multicollinearity** was carefully addressed, with any variables that had a VIF value greater than 5 removed to avoid inflated standard errors. Additionally, the model assumes a **large sample size**, and with over 4,000 rows in the dataset, this assumption was comfortably met.

To further refine the model, hyperparameter tuning was used to adjust the classification threshold for predicting whether clients would subscribe to the term deposit. To address class imbalance in the target variable, a balanced dataset was created through oversampling the minority class. Once the final logistic regression model was built, performance metrics such as accuracy, specificity, and sensitivity were evaluated using confusion matrices. The model’s results were further validated through resampling to ensure consistent performance across various subsets of the data.

# Data

<!-- 
Purpose: Explain the data used in the analysis and any preprocessing steps.
Instructions: Provide an overview of the dataset, variables, and any cleaning steps or transformations made. Mention variables used or excluded and why.
-->

The dataset contains 4,119 rows and 21 variables. The variables are split between 11 categorical (character type) and 10 numeric variables. In preparation for analysis, categorical variables were converted into factors to ensure proper handling in models. The target variable, y, was converted into a binary outcome where "yes" was mapped to 1, indicating that the client subscribed to a term deposit, and "no" was mapped to 0.

```{r, echo=FALSE}
skim(df3)
```

During exploratory data analysis (EDA), several visualizations were used to understand the distribution and relationships within the dataset. Box plots were employed to visualize the distribution of numeric variables such as **age**, **campaign**, **emp.var.rate**, **cons.price.idx**, **cons.conf.idx**, **euribor3m**, and **nr.employed**, grouped by whether the client subscribed to a deposit. These plots helped identify the differences in distributions between those who subscribed and those who did not.

Additionally, bar plots were used to visualize the distribution of categorical variables such as **job**, **marital status**, **education**, **default**, **housing**, **loan**, **contact**, **month**, **day_of_week**, and **poutcome**. These visuals highlighted the relative frequencies of each category in relation to the target outcome, providing insights into which factors may be more predictive of a client's decision to subscribe.

Make a note to talk about pdays: 999 means no and and other number means yes they have been previsouly contacted. We changed this to binary yes they have been previsouls contacted or no the have not been preivouls contacted.

To further explore relationships between numeric variables, a correlation matrix was generated, with a corresponding heatmap to visually represent the strength of correlations between variables.
```{r,echo=FALSE}


# Transforming the dataframe to long format
df_long <- df3 %>%
  pivot_longer(cols = c(age, campaign, emp.var.rate, cons.price.idx, cons.conf.idx, euribor3m, nr.employed), 
               names_to = "variable", values_to = "value")

# Creating the boxplots for all variables
ggplot(df_long, aes(x = as.factor(y), y = value)) +
  geom_boxplot() +
  facet_wrap(~variable, scales = "free") +
  labs(x = "y", y = "Value") +
  theme_minimal()


# Convert 'previous' and 'pcontact' to factors
dflong2 <- df3 %>% mutate(
  previous = as.factor(previous),
  pcontact = as.factor(pcontact)
)

# Transforming the dataframe to long format
df_long2 <- dflong2 %>%
  pivot_longer(cols = c(job, marital, education, default, housing, loan, contact, month, day_of_week, poutcome, previous, pcontact),
               names_to = "variable", values_to = "value")

# Creating bar plots for all categorical variables
ggplot(df_long2, aes(fill = as.factor(y), x = value)) +
  geom_bar(position = "dodge") +
  facet_wrap(~variable, scales = "free_x", nrow = 3) +  # Set nrow for larger facet grid
  labs(x = "Variable", y = "Count", fill = "y") +
  ylim(0, 4000) +  # Set y-axis limits from 0 to 4000
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 8),  # Adjust text angle and size
    strip.text = element_text(size = 10)  # Increase facet label size
  )

cor1 <- df3 %>% select_if(is.numeric) %>% cor()
corrplot(cor1)


```

# Findings

<!-- 
Purpose: Present the results of the analysis.
Instructions: Report accuracy rates and compare the performance of models. Discuss significant variables or interactions discovered.
-->
 
```{r}
df4 <- df3 %>% dplyr::select(!duration)
```






```{r}
# Split data into training and testing samples
# Setting seed locks the random number generator. 
set.seed(321)
trn_part <- sample(nrow(df4),0.8*nrow(df4),replace = F) # Setting training sample to be 80% of the data
dftrain <- df4[trn_part,]
dftest <- df4[-trn_part,]

## Resample with more balanced data 
df_sub = df4 %>% filter(y == 1)
df_no_sub = df4 %>% filter(y == 0)
sample_no_sub = sample_n(df_no_sub, nrow(df_sub))
df_bal = rbind(sample_no_sub,df_sub)

# Split data into training and testing balanced samples
set.seed(321)
tr_ind_bal <- sample(nrow(df_bal), 0.8 * nrow(df_bal), replace = FALSE) # Setting training sample to be 80% of the balanced data
dftrain_bal <- df_bal[tr_ind_bal, ]
dftest_bal <- df_bal[-tr_ind_bal, ]



# Variable selection - reduce model complexity using stepwise backward elimination
m7.log = step(glm(as.factor(y) ~ . - loan - emp.var.rate - euribor3m, data = dftrain_bal, family = binomial), direction = "backward")

# Check the summary and VIF of the final model
summary(m7.log)
vif(m7.log)  # Double-check multicollinearity

# Predict the responses on the balanced testing data using the reduced model
predprob2_log_bal <- predict(m7.log, newdata = dftest_bal, type = "response")  # Predict probabilities for the test set
predclass2_log_bal <- ifelse(predprob2_log_bal >= 0.5, 1, 0)  # Classify based on the threshold

# Compare to actual results using the confusion matrix
caret::confusionMatrix(as.factor(predclass2_log_bal), as.factor(dftest_bal$y), positive = "1")
```

```{r}
pred_bal <- prediction(predprob2_log_bal,dftest_bal$y) #Predicted Probability and True Classification

auc_bal <- round(as.numeric(performance(pred_bal, measure = "auc")@y.values),3)

# computing threshold for cutoff to best trade off sensitivity and specificity, unbalanced first
#first sensitivity
plot(unlist(performance(pred_bal, "sens")@x.values), unlist(performance(pred_bal, "sens")@y.values), 
     type="l", lwd=2, 
     ylab="Sensitivity", xlab="Cutoff", main = paste("Maximized Cutoff\n","AUC: ",auc_bal))

par(new=TRUE) # plot another line in same plot

#second specificity
plot(unlist(performance(pred_bal, "spec")@x.values), unlist(performance(pred_bal, "spec")@y.values), 
     type="l", lwd=2, col='red', ylab="", xlab="")
axis(4, at=seq(0,1,0.2)) #specificity axis labels
mtext("Specificity",side=4, col='red')

#find where the lines intersect
min.diff_bal <-which.min(abs(unlist(performance(pred_bal, "sens")@y.values) - unlist(performance(pred_bal, "spec")@y.values)))
min.x_bal<-unlist(performance(pred_bal, "sens")@x.values)[min.diff_bal]
min.y_bal<-unlist(performance(pred_bal, "spec")@y.values)[min.diff_bal]
optimal_bal <-min.x_bal #this is the optimal points to best trade off sensitivity and specificity

abline(h = min.y_bal, lty = 3)
abline(v = min.x_bal, lty = 3)
text(min.x_bal,0,paste("optimal threshold=",round(optimal_bal,2)), pos = 3)

pr_class_bal = ifelse(predprob2_log_bal>optimal_bal, 1,0) #use the optimal cutoff to classify
caret::confusionMatrix(as.factor(pr_class_bal),as.factor(dftest_bal$y)) #this function and package auto computes a lot of the metrics
```
 
 Split data set, 
 Whil performing LOGREG checked VIF Funciton to check for multi=colinearity and removed those above 5
 did backwards AIC elimination for reomove (insert variables removed)
Logist Regression with these variables (- loan - emp.var.rate - euribor3m
age           
contact       
month     
campaign      
cons.conf.idx
nr.employed
pcontact)
Confusion matrix here:
We found that the data still seem skewed after it was balanced so we adjusted the cut-off threshold optimization.
LDA confusion matrix for LDA model
# Conclusion

<!-- 
Purpose: Summarize the key takeaways and provide actionable recommendations.
Instructions: Conclude with the most important findings and offer suggestions for further analysis or improvements.
-->

Content for Conclusion goes here.

# Appendix

<!-- 
Purpose: Include supplementary material or detailed technical results.
Instructions: Provide code snippets, detailed model output, and data summaries.
-->

Content for Appendix goes here.
