---
title: "Case Study 3 Sandbox"
format: html
---

## Case Study 3 Sandbox

```{r setup}
pacman::p_load(tidyverse, here, skimr, rpart, dplyr, VIM, corrplot, car, quantmod, ggplot2, tree, e1071, MASS)
```

```{r}
raw_index_data <- read.csv(here('Case Study 3', 'dow_jones_index.data'))
raw_index_names <- read.csv(here('Case Study 3', 'dow_jones_index.names'))
```


```{r}
str(raw_index_data)
```
```{r}
skim(raw_index_data)
```


```{r}
anyNA(raw_index_data)
```
#It appears we have missing values, We will need to address this in some of our next steps but first we'll divide the data into train and test

```{r}
missing_values <- colSums(is.na(raw_index_data))

missing_values
```
#Splitting data into training (Q1) and testing (Q2)

```{r}

train_data <- subset(raw_index_data, quarter == 1)  # Training data (Q1: Jan-Mar)
test_data <- subset(raw_index_data, quarter == 2)   # Testing data (Q2: Apr-Jun)

```

#Running correlation check among the numeric variables

```{r}

cor_matrix <- cor(train_data[, sapply(train_data, is.numeric)], use = "complete.obs")

cor_matrix
```
#There appears to be correlation between 'volume' and keep 'previous_weeks_volume'-these two had >.8 (high correlation). Which one would be important to keep for predicting our target variable [percent_change_next_weeks_price]?

#I've decided to parse out the data variables I believe will be most useful moving forward

```{r}

selected_vars <- c('date', 'stock', "percent_change_next_weeks_price", "percent_change_price", 
                   "percent_change_volume_over_last_wk", "previous_weeks_volume", 
                   "days_to_next_dividend", "percent_return_next_dividend", 
                   "open", "high", "low", "close")

train_data_filtered <- train_data[,selected_vars]


test_data_filtered <- test_data[,selected_vars]
  

```

No issue with the variables selected except no date or stock variable?

#Convert necessary columns to numeric

```{r}

train_data_filtered <- train_data_filtered %>%
  mutate(across(c(open, high, low, close), ~ as.numeric(gsub("[$,]", "", .))))  # Clean and convert

test_data_filtered <- test_data_filtered %>%
  mutate(across(c(open, high, low, close), ~ as.numeric(gsub("[$,]", "", .)))) 

```

#impute missing values using KNN in order to maintain integrity of any data patterns

```{r}

# KNN imputation on the training data
train_data_imputed <- kNN(train_data_filtered, variable = c("percent_change_volume_over_last_wk", "previous_weeks_volume"), 
                          k = 5, imp_var = F)  # Adjust k (number of neighbors) as necessary

# Should return 'FALSE' if no missing values
anyNA(train_data_imputed)

```

Variables were selected before but here you went back to your original un-selected training dataset. Adjusted to go with the datset with variable selections. I'm pretty neutral on imputing the data, my only concern here is that we may need to explain reasoning for choosing KNN imputation, and check assumptions for using this method. My original gut check with this is too assume the same volume change, so percent_change_over_last_week would be zero for imputed values, and previous_weeks_volume would equal volume.

#Apply scaling in prep for modeling

```{r}

normalize_min_max <- function(x) {
  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}

train_data_scaled <- train_data_imputed %>%
  mutate(across(where(is.numeric), normalize_min_max))

test_data_scaled <- test_data_filtered %>%
  mutate(across(where(is.numeric), normalize_min_max))

```


#Chage Date variable to true date

```{r}
train_data_scaled <- train_data_scaled %>% 
  mutate(date = parse_date_time(date, '%m/%d/%Y'))

test_data_scaled <- test_data_scaled %>% 
  mutate(date = parse_date_time(date, '%m/%d/%Y'))
```


#Create lagged Variables on scaled data

```{r}
train_data_scaled %>%
  arrange(date) %>%  
  mutate(
    percent_change_price_lag1 = lag(percent_change_price) 
  ) %>% head()
```

Previous method to lag variables does not account for the stock itself. So lag value when ordered by date will pull the values for same date across different stocks.

#Create lagged variables on scaled data version 2

```{r}
train_data_scaled <- train_data_scaled %>%
  group_by(stock) %>% 
  arrange(date) %>%  
  mutate(
    percent_change_price_lag1 = lag(percent_change_price, n = 4) 
  ) %>% ungroup()

test_data_scaled <- test_data_scaled %>%
  group_by(stock) %>% 
  arrange(date) %>%  
  mutate(
    percent_change_price_lag1 = lag(percent_change_price, n = 4) 
  ) %>% ungroup()
```

Group by should solve earlier issue

#Plotting the lagged variables to visualize correlation

```{r}

ggplot(train_data_scaled, aes(x = percent_change_price_lag1, y = percent_change_price)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", color = "blue", se = FALSE) +
  labs(
    title = "Lagged Variable Plot: Percentage Change in Price (t) vs (t-1)",
    x = "Percentage Change in Price (t-4)",
    y = "Percentage Change in Price (t)"
  ) +
  theme_minimal()

```

#Now applying data subset variables to a regression tree, our target variable is [percent_change_next_weeks_price] so we're going to use this regression tree to assess our features importance (which ones are most predictive?)

#wrapper outside of tree model/use for loop == stock name/store rmse/mape into frame

```{r}

tree_model <- rpart(percent_change_next_weeks_price ~ ., data = train_data_scaled, method = "anova")

print(tree_model)
printcp(tree_model)  

plot(tree_model, uniform = TRUE, main = "Regression Tree for Stock Price Prediction")
text(tree_model, use.n = TRUE, all = TRUE, cex = 0.7)

```

#this looks nuts, not sure what to change to make it better


#gonna try pruning, also using Dr. Roy methods for creating tree

```{r}
set.seed(123)

lagtree <- tree(percent_change_next_weeks_price ~ ., data = train_data_scaled)

# If needed, pruning can be performed by specifying the "best" argument 
cv.lag <- cv.tree(lagtree)
best_size <- cv.lag$size[which.min(cv.lag$dev)]
prune.lag <- prune.tree(lagtree, best = best_size)
summary(prune.lag)
print(best_size)


# Get predictions on the test data 
dtpreds <- predict(lagtree, newdata = test_data_scaled)
testpreds <- data.frame(date = test_data_scaled$date,
                        stock = test_data_scaled$stock,
                        response = test_data_scaled$percent_change_next_weeks_price,
                        dt = dtpreds)

mse_dt = mean((testpreds$response - testpreds$dt)^2)
mae_dt = mean(abs(testpreds$response - testpreds$dt))
me_dt = mean(testpreds$response - testpreds$dt)
mape_dt = mean(abs(testpreds$response - testpreds$dt)*100/testpreds$response)

testperfs <- data.frame(dt = c(mse_dt, mae_dt, me_dt, mape_dt)
                        ) %>% t()
colnames(testperfs) <- c('mse', 'mae', 'me', 'mape')
print('')
print(testperfs)
```

after pruning, best size given is 1, which likely means decision tree won't work out well anyway. but opting for no pruning for preds, we can always change this

Mape will always be Inf because of zero values for response. Probably don't even need to include it, but i have it anyway in case we need to talk about why we don't have it.

# Linear model

```{r}
lmfit1 <- step(lm(percent_change_next_weeks_price ~ ., data = na.omit(train_data_scaled)), method = 'both')
summary(lmfit1)
lmpreds <- predict(lmfit1, test_data_scaled)

testpreds$lm <- lmpreds

mse_lm = mean((testpreds$response - testpreds$lm)^2)
mae_lm = mean(abs(testpreds$response - testpreds$lm))
me_lm = mean(testpreds$response - testpreds$lm)
mape_lm = mean(abs(testpreds$response - testpreds$lm)*100/testpreds$response)

testperfs <- rbind(testperfs, lm = c(mse_lm, mae_lm, me_lm, mape_lm))
print(testperfs)
```

I had issues with missing values from the lag variable, so may need to bring this up to the professor later.

```{r}
plot(lmfit1)
```


# SVR

```{r}
form1 <- percent_change_next_weeks_price ~ .
svr_tune1 <- tune.svm(form1, data = train_data_scaled, gamma = seq(.01,.1, by = .01), cost = seq(.1, 1, by = .1), scale = T)
```

```{r}
bestParams <- svr_tune1$best.parameters
print(bestParams)
```


```{r}
svrfit1 <- svm(form1, data = train_data_scaled, gamma = bestParams$gamma, cost = bestParams$cost, scale = T)
summary(svrfit1)
```

```{r}
svrpreds <- predict(svrfit1, test_data_scaled)
#testpreds$svr <- svrpreds

mse_svr = mean((na.omit(testpreds$response) - svrpreds)^2)
mae_svr = mean(abs(na.omit(testpreds$response) - svrpreds))
me_svr = mean(na.omit(testpreds$response) - svrpreds)
mape_svr = mean(abs(na.omit(testpreds$response) - svrpreds)*100/na.omit(testpreds$response))

testperfs <- rbind(testperfs, svr = c(mse_svr, mae_svr, me_svr, mape_svr))
print('')
print(testperfs)
```

SVR won't accept the missing values in the lag variable so it just omits them. This means it won't let me add the SVR predictions to the preds dataset. We can still calculate our performance metrics it's just ugly getting there.
This might be a case for adding the lag variable prior to the split, but that's also iffy because that would mean there would be response observations from the training data in the predictors of the test data, which seems wrong.


Questions for Dr. Roy:
1. Create Lag variable before or after test train split? Same for lag plots? Creates loss of observations in test when done after.
2. Group by for lag variable calculation?
3. Lag variable keeps getting eliminated in step function for lm, should it be?
4. KNN imputation appropriate for missing values?
5. Tree pruning returns 1 node?



